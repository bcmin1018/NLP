{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic_comment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcmin1018/NLP/blob/main/Classification/Toxic_comment_classification/Notebooks/Toxic_comment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl6FnyWREn3J",
        "outputId": "a7396fbe-2fb0-45dc-df12-60ea68eca0dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 20.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 19.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "metadata": {
        "id": "8822sFwqETLS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTsYfLgObJYu",
        "outputId": "8c4bb9f9-6bec-457b-dafc-99b527ead388"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1-0kJHNDTDLvx8U7hrN9kq9T3aLaWI6wW\n",
        "!gdown --id 1fh2Wtzjx7t9mIv6-ntUB-dv27nfJfFba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qORTvYDmaJtd",
        "outputId": "191ea8b6-496d-485a-9212-eca90ff88791"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0kJHNDTDLvx8U7hrN9kq9T3aLaWI6wW\n",
            "To: /content/jigsaw-unintended-bias-train(clean).csv\n",
            "100% 1.43G/1.43G [00:26<00:00, 54.3MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fh2Wtzjx7t9mIv6-ntUB-dv27nfJfFba\n",
            "To: /content/validation.csv\n",
            "100% 3.18M/3.18M [00:00<00:00, 251MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path= \"./jigsaw-unintended-bias-train(clean).csv\"\n",
        "valid_data_path= \"./validation.csv\"\n",
        "train_data = pd.read_csv(train_data_path, lineterminator='\\n', usecols=['clean_comment_text','toxic'])\n",
        "valid_data = pd.read_csv(valid_data_path, usecols=['comment_text','toxic'])"
      ],
      "metadata": {
        "id": "WX7WSOiyaqrF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = train_data[0:16]\n",
        "df_valid = valid_data[0:16]"
      ],
      "metadata": {
        "id": "zmEUSYJccGwp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GO2K7m7TCRjj"
      },
      "outputs": [],
      "source": [
        "# dataset.py\n",
        "class BERTDataset:\n",
        "  def __init__(self, comment_text, target):\n",
        "    self.comment_text = comment_text\n",
        "    self.target = target\n",
        "    self.tokenizer = TOKENIZER\n",
        "    self.max_len = MAX_LEN\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comment_text)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    comment_text = str(self.comment_text[item])\n",
        "    comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "    inputs = self.tokenizer.encode_plus(\n",
        "        comment_text,\n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        truncation=True,\n",
        "        max_length = self.max_len\n",
        "    )\n",
        "\n",
        "    ids = inputs[\"input_ids\"]\n",
        "    mask = inputs['attention_mask']\n",
        "    token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "    padding_length = self.max_len - len(ids)\n",
        "    ids = ids + ([0] * padding_length)\n",
        "    mask = mask + ([0] * padding_length)\n",
        "    token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "\n",
        "    return {\n",
        "        'ids' : torch.tensor(ids, dtype=torch.long),\n",
        "        'mask' : torch.tensor(mask, dtype=torch.long),\n",
        "        'token_type_ids' : torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        'target' : torch.tensor(self.target[item], dtype=torch.float)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "\n",
        "class BERTBaseUncased(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BERTBaseUncased, self).__init__()\n",
        "    self.bert = transformers.BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "    self.bert_drop = nn.Dropout(0.3)\n",
        "    #mean, max pooling (768 * 2)\n",
        "    self.out = nn.Linear(768, 1)\n",
        "\n",
        "  def forward(self, ids, mask, token_type_ids):\n",
        "    outputs = self.bert(\n",
        "        ids,\n",
        "        attention_mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        "    )\n",
        "\n",
        "    # mean_pooling = torch.mean(outputs[1], 1)\n",
        "    # max_pooling, _ = torch.max(outputs[1], 1)\n",
        "    # cat = torch.cat((mean_pooling, max_pooling), 1)\n",
        "\n",
        "    # bo = self.bert_drop(cat)\n",
        "    # output = self.out(bo)\n",
        "    output = self.out(outputs[1])\n",
        "    return output"
      ],
      "metadata": {
        "id": "KC4g6cNVEWTM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#engine.py\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "  return F.cross_entropy(outputs, targets.view(-1, 1).float())\n",
        "\n",
        "def train(data_loader, model, optimizer, device, scheduler):\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "    ids = data['ids']\n",
        "    token_type_ids = data['token_type_ids']\n",
        "    mask = data['mask']\n",
        "    targets = data['target']\n",
        "\n",
        "    ids = ids.to(device, dtype=torch.long)\n",
        "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "    mask = mask.to(device, dtype=torch.long)\n",
        "    targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(\n",
        "        ids = ids,\n",
        "        mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        "    )\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "def eval(data_loader, model, device):\n",
        "  model.eval()\n",
        "  fin_targets = []\n",
        "  fin_outputs = []\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "      ids = data['ids']\n",
        "      token_type_ids = data['token_type_ids']\n",
        "      mask = data['mask']\n",
        "      targets = data['target']\n",
        "\n",
        "      ids = ids.to(device, dtype=torch.long)\n",
        "      token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "      mask = mask.to(device, dtype=torch.long)\n",
        "      targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "      outputs = model(\n",
        "        ids = ids,\n",
        "        mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        "      )\n",
        "\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "  return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "sai52AShG_E0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "\n",
        "MAX_LEN = 100\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LR = 3e-5\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab Notebooks/model.pt\"\n",
        "TOKENIZER = transformers.BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "_0fxVf42JbQE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "i7EtrYw6KEAR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataset(\n",
        "    comment_text = df_train.clean_comment_text.values,\n",
        "    target = df_train.toxic.values\n",
        ")\n",
        "\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = TRAIN_BATCH_SIZE,\n",
        "    num_workers = 2\n",
        ")\n",
        "valid_dataset = BERTDataset(\n",
        "    comment_text = df_valid.comment_text.values,\n",
        "    target = df_valid.toxic.values\n",
        ")\n",
        "\n",
        "valid_data_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = VALID_BATCH_SIZE,\n",
        "    num_workers = 1\n",
        ")"
      ],
      "metadata": {
        "id": "lpt6wnFjcPXZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = BERTBaseUncased()\n",
        "model.to(device)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "optimizer_parameters = [\n",
        "  {'params' : [p for n, p in param_optimizer if not any (nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "  {'params' : [p for n, p in param_optimizer if any (nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "optimizer = AdamW(optimizer_parameters, lr = LR)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = num_train_steps)\n",
        "\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "  train(train_data_loader, model, optimizer, device, scheduler)\n",
        "  outputs, targets = eval(valid_data_loader, model, device)\n",
        "  # targets = np.array(targets) >= 0.5\n",
        "  accuracy = metrics.roc_auc_score(targets, outputs)\n",
        "  print((f\"AUC Score = {accuracy}\"))\n",
        "  if accuracy > best_accuracy:\n",
        "    torch.save(model.state_dict(), MODEL_PATH)\n",
        "    best_accuarcy = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmWRjLSRq1fU",
        "outputId": "12a26801-ebd8-40fe-c0ab-27ffc5478eae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score = 0.33333333333333337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score = 0.33333333333333337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score = 0.33333333333333337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score = 0.33333333333333337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score = 0.33333333333333337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "  # # df1 = pd.read_csv\n",
        "  # df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/jigsaw-unintended-bias-train(clean).csv',lineterminator='\\n', usecols=['clean_comment_text','toxic'])\n",
        "  # df_train = df_train.iloc[0:100]\n",
        "\n",
        "  # # df_train = pad.concat([df1, df2], axis=0, reset_index(drop=True)\n",
        "\n",
        "  # df_valid = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/validation.csv')\n",
        "\n",
        "  train_dataset = BERTDataset(\n",
        "      comment_text = df_train.clean_comment_text.values,\n",
        "      target = df_train.toxic.values\n",
        "  )\n",
        "\n",
        "  train_data_loader = DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size = TRAIN_BATCH_SIZE,\n",
        "      num_workers = 2\n",
        "  )\n",
        "\n",
        "  valid_dataset = BERTDataset(\n",
        "     comment_text = df_valid.comment_text.values,\n",
        "     target = df_valid.toxic.values\n",
        "  )\n",
        "\n",
        "  valid_data_loader = DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size = VALID_BATCH_SIZE,\n",
        "      num_workers = 1\n",
        "  )\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "  model = BERTBaseUncased()\n",
        "  model.to(device)\n",
        "\n",
        "  param_optimizer = list(model.named_parameters())\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_parameters = [\n",
        "    {'params' : [p for n, p in param_optimizer if not any (nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "    {'params' : [p for n, p in param_optimizer if any (nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "  ]\n",
        "\n",
        "  num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "  optimizer = AdamW(optimizer_parameters, lr = LR)\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0,\n",
        "                                              num_training_steps = num_train_steps)\n",
        "  \n",
        "  best_accuracy = 0\n",
        "  for epoch in range(EPOCHS):\n",
        "    train(train_data_loader, model, optimizer, device, scheduler)\n",
        "    outputs, targets = eval(valid_data_loader, model, device)\n",
        "    targets = np.array(targets) >= 0.5\n",
        "    accuracy = metrics.roc_auc_score(targets, outputs)\n",
        "    print((f\"AUC Score = {accuracy}\"))\n",
        "    if accuracy > best_accuracy:\n",
        "      torch.save(model.state_dict(), MODEL_PATH)\n",
        "      best_accuarcy = accuracy"
      ],
      "metadata": {
        "id": "UZOCZJdWKQqy"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "4zPSra2wMGBn",
        "outputId": "16957a72-fc51-4f76-c15d-857672af1a3f"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-117-59029771f93a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-21d03c41eccb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-21d03c41eccb>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(outputs, targets)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NHh9uzOuiYCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트코드"
      ],
      "metadata": {
        "id": "FV4Ba5qwiX_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert = transformers.BertModel.from_pretrained('bert-base-multilingual-cased').to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3HWKEEfpVlQ",
        "outputId": "e4e00ebb-f4df-4747-b8b6-4b4854e753a2"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, data in tqdm(enumerate(train_data_loader), total=len(train_data_loader)):\n",
        "   ids = data['ids']\n",
        "   token_type_ids = data['token_type_ids']\n",
        "   mask = data['mask']\n",
        "   targets = data['target']\n",
        "\n",
        "   ids = ids.to(device, dtype=torch.long)\n",
        "   token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "   mask = mask.to(device, dtype=torch.long)\n",
        "   targets = targets.to(device, dtype=torch.long)\n",
        "   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTg589-HiW3T",
        "outputId": "6baf867e-dacb-4dc3-bc98-3272046a7125"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n",
        "outputs = model(\n",
        "    ids = ids,\n",
        "    mask = mask,\n",
        "    token_type_ids = token_type_ids\n",
        ")"
      ],
      "metadata": {
        "id": "y8mdGtB_rQVD"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJiuK8ArdqX",
        "outputId": "dbe9b5cd-ea35-4bcc-b039-f2e38cc2b3f8"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2003],\n",
              "        [-0.1755],\n",
              "        [-0.2037],\n",
              "        [-0.1443],\n",
              "        [-0.2161],\n",
              "        [-0.1625],\n",
              "        [-0.2250],\n",
              "        [-0.2844],\n",
              "        [-0.3807],\n",
              "        [-0.1863],\n",
              "        [-0.2765],\n",
              "        [-0.2312],\n",
              "        [-0.2147],\n",
              "        [-0.2694],\n",
              "        [-0.3177],\n",
              "        [-0.1931]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets.view(-1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPEf5VEargA6",
        "outputId": "1b3b5b5a-06a3-45bc-a3f0-35059ab11a64"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(outputs, targets.float())"
      ],
      "metadata": {
        "id": "Bel6XK85rbZO"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuwkDGTErpVS",
        "outputId": "c9f5bdce-c272-474c-ee45-44371c993d77"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0., device='cuda:0', grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = bert(\n",
        "        ids,\n",
        "        attention_mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        ")"
      ],
      "metadata": {
        "id": "ZUw_F-OQpcBV"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = nn.Linear(768, 1).to(device)"
      ],
      "metadata": {
        "id": "9itl9ujnp9Cu"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out(outputs[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4nPrRC5pl1W",
        "outputId": "5f286de5-a77a-4c1a-c106-59d4b64c894c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4839],\n",
              "        [0.4113],\n",
              "        [0.4250],\n",
              "        [0.3696],\n",
              "        [0.3300],\n",
              "        [0.2585],\n",
              "        [0.2929],\n",
              "        [0.2718],\n",
              "        [0.4765],\n",
              "        [0.4958],\n",
              "        [0.4319],\n",
              "        [0.3376],\n",
              "        [0.3643],\n",
              "        [0.4480],\n",
              "        [0.2355],\n",
              "        [0.3274]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = BERTBaseUncased().to(device)"
      ],
      "metadata": {
        "id": "E7diU20SigXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a743945e-37fd-4751-8b4c-95b3f130b1af"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bert = transformers.BertModel.from_pretrained('bert-base-multilingual-cased').to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtaEHjDYikqQ",
        "outputId": "da344c77-89fe-4d15-aa0c-fcff6c4cb424"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(\n",
        "        ids = ids,\n",
        "        mask = mask,\n",
        "        token_type_ids = token_type_ids)"
      ],
      "metadata": {
        "id": "NVxgNJ3mjYEm"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA2aqQDKomel",
        "outputId": "375c4efe-f0bd-40d9-b455-ab6b9b44e9dc"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, targets = eval(valid_data_loader, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6PhIMJOqgXL",
        "outputId": "eae6fc27-de07-421a-f879-6594b8aafcea"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  2.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.roc_auc_score(targets, outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kphvTxGapulG",
        "outputId": "946a268a-40a4-4ed1-ef45-2125619c6a5f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZdKJ0T5ouzV",
        "outputId": "05c1d671-f186-45e7-be6e-24bdcb234db5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(targets) >= 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ly0AtKblzOI",
        "outputId": "5c0ed90e-0c53-409e-b3da-f3f768387985"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.array(targets) >= 0.5\n",
        "    accuracy = metrics.roc_auc_score(targets, outputs)"
      ],
      "metadata": {
        "id": "UePjv0-nirS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "11bf28bb-4b9b-4cef-8bf9-76eb44c2f763"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-e518f864067f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'view'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = nn.Linear(768, 1).to(device)"
      ],
      "metadata": {
        "id": "3NDeWTgNmaNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = out(outputs[0])"
      ],
      "metadata": {
        "id": "w3O1BealmV5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o = torch.sigmoid(output[0]).cpu().detach().numpy().tolist()"
      ],
      "metadata": {
        "id": "TwSf4n4Y0QFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = targets.cpu().detach().numpy().tolist()\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXX9lSUatcHA",
        "outputId": "4a67171f-d3eb-4328-c6b2-c217f9234786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = F.cross_entropy(output, targets.view(-1, 1))"
      ],
      "metadata": {
        "id": "usWAzPKctj4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = np.array(t) >= 0.5\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhIXg7hAt9KG",
        "outputId": "28b72899-1c5b-46ae-aa95-c2cbb4577f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.roc_auc_score(t2, o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "daamrfvsw4Xc",
        "outputId": "02cb7369-b197-4905-e08e-254e7fbb6331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-eacf23537d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         )\n\u001b[1;32m    574\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         raise ValueError(\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"is not defined in that case.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.roc_auc_score(targets, outputs)"
      ],
      "metadata": {
        "id": "rWm7eYfhydib",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "b45c6016-2e9d-4b82-85ee-43405e806ea1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-e18f1a8406d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     if y_type == \"multiclass\" or (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m             raise ValueError(\n\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             )\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qVZe5Mhoj354"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}