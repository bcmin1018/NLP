{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic_comment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7400736a8c44148ac737f33af6bc103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3eeb5a7ff311441d9d9d0b90f5951629",
              "IPY_MODEL_ec56ae0e641a4282887d8c373584022e",
              "IPY_MODEL_d7a6a45f061c468899f26b79e1d2d806"
            ],
            "layout": "IPY_MODEL_fd112ab14443468f90adfaeb906eb4cb"
          }
        },
        "3eeb5a7ff311441d9d9d0b90f5951629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337b2d3655c54b089a3cd1ff0181986f",
            "placeholder": "​",
            "style": "IPY_MODEL_368cf1536d2f4c45a9e87aa32a0fedb9",
            "value": "Downloading: 100%"
          }
        },
        "ec56ae0e641a4282887d8c373584022e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_440294808f7b4c25959018506dc26231",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a5caffc4c184a96978f06362364fe50",
            "value": 714314041
          }
        },
        "d7a6a45f061c468899f26b79e1d2d806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09162f2e24854fbfb73665f978456d05",
            "placeholder": "​",
            "style": "IPY_MODEL_9f01c972a9644c039890ea852889ad4d",
            "value": " 681M/681M [00:11&lt;00:00, 63.4MB/s]"
          }
        },
        "fd112ab14443468f90adfaeb906eb4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337b2d3655c54b089a3cd1ff0181986f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368cf1536d2f4c45a9e87aa32a0fedb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "440294808f7b4c25959018506dc26231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5caffc4c184a96978f06362364fe50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09162f2e24854fbfb73665f978456d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f01c972a9644c039890ea852889ad4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcmin1018/NLP/blob/main/Classification/Toxic_comment_classification/Notebooks/Toxic_comment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "hl6FnyWREn3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "8822sFwqETLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTsYfLgObJYu",
        "outputId": "98f1b37d-0f1c-4297-ebe4-aabaa47a9838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1-0kJHNDTDLvx8U7hrN9kq9T3aLaWI6wW\n",
        "!gdown --id 1fh2Wtzjx7t9mIv6-ntUB-dv27nfJfFba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qORTvYDmaJtd",
        "outputId": "cb7b3d23-68c3-46bb-80db-d1950cbd3802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0kJHNDTDLvx8U7hrN9kq9T3aLaWI6wW\n",
            "To: /content/jigsaw-unintended-bias-train(clean).csv\n",
            "100% 1.43G/1.43G [00:05<00:00, 259MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fh2Wtzjx7t9mIv6-ntUB-dv27nfJfFba\n",
            "To: /content/validation.csv\n",
            "100% 3.18M/3.18M [00:00<00:00, 195MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path= \"./jigsaw-unintended-bias-train(clean).csv\"\n",
        "valid_data_path= \"./validation.csv\"\n",
        "train_data = pd.read_csv(train_data_path, lineterminator='\\n', usecols=['clean_comment_text','toxic'])\n",
        "valid_data = pd.read_csv(valid_data_path, usecols=['comment_text','toxic'])"
      ],
      "metadata": {
        "id": "WX7WSOiyaqrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = train_data[0:100]\n",
        "df_valid = valid_data[0:100]"
      ],
      "metadata": {
        "id": "zmEUSYJccGwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO2K7m7TCRjj"
      },
      "outputs": [],
      "source": [
        "# dataset.py\n",
        "class BERTDataset:\n",
        "  def __init__(self, comment_text, target):\n",
        "    self.comment_text = comment_text\n",
        "    self.target = target\n",
        "    self.tokenizer = TOKENIZER\n",
        "    self.max_len = MAX_LEN\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comment_text)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    comment_text = str(self.comment_text[item])\n",
        "    comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "    inputs = self.tokenizer.encode_plus(\n",
        "        comment_text,\n",
        "        None,\n",
        "        add_special_tokens=True,\n",
        "        truncation=True,\n",
        "        max_length = self.max_len\n",
        "    )\n",
        "\n",
        "    ids = inputs[\"input_ids\"]\n",
        "    mask = inputs['attention_mask']\n",
        "    token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "    padding_length = self.max_len - len(ids)\n",
        "    ids = ids + ([0] * padding_length)\n",
        "    mask = mask + ([0] * padding_length)\n",
        "    token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "\n",
        "    return {\n",
        "        'ids' : torch.tensor(ids, dtype=torch.long),\n",
        "        'mask' : torch.tensor(mask, dtype=torch.long),\n",
        "        'token_type_ids' : torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        'target' : torch.tensor(self.target[item], dtype=torch.float)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "\n",
        "class BERTBaseUncased(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BERTBaseUncased, self).__init__()\n",
        "    self.bert = transformers.BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "    self.bert_drop = nn.Dropout(0.3)\n",
        "    # mean, max pooling (768 * 2)\n",
        "    self.out = nn.Linear(768 * 2, 1)\n",
        "\n",
        "  def forward(self, ids, mask, token_type_ids):\n",
        "    outputs = self.bert(\n",
        "        ids,\n",
        "        attention_mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        "    )\n",
        "\n",
        "    mean_pooling = torch.mean(outputs[0], 1)\n",
        "    max_pooling, _ = torch.max(outputs[0], 1)\n",
        "    cat = torch.cat((mean_pooling, max_pooling), 1)\n",
        "\n",
        "    bo = self.bert_drop(cat)\n",
        "    output = self.out(bo)\n",
        "    return output"
      ],
      "metadata": {
        "id": "KC4g6cNVEWTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#engine.py\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "  return nn.BCEWithLogitsLoss()(outputs, targets.float().view(-1, 1))\n",
        "\n",
        "def train(data_loader, model, optimizer, device, scheduler):\n",
        "  model.train()\n",
        "  avg_loss = 0\n",
        "  for batch_idx, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "    ids = data['ids']\n",
        "    token_type_ids = data['token_type_ids']\n",
        "    mask = data['mask']\n",
        "    targets = data['target']\n",
        "\n",
        "    ids = ids.to(device, dtype=torch.long)\n",
        "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "    mask = mask.to(device, dtype=torch.long)\n",
        "    targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(\n",
        "        ids = ids,\n",
        "        mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        "    )\n",
        "\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    if batch_idx % 10 == 0:\n",
        "      print(f'bi={batch_idx}, loss={loss}')\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "def eval(data_loader, model, device):\n",
        "  model.eval()\n",
        "  fin_targets = []\n",
        "  fin_outputs = []\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
        "      ids = data['ids']\n",
        "      token_type_ids = data['token_type_ids']\n",
        "      mask = data['mask']\n",
        "      targets = data['target']\n",
        "\n",
        "      ids = ids.to(device, dtype=torch.long)\n",
        "      token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "      mask = mask.to(device, dtype=torch.long)\n",
        "      targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "      outputs = model(\n",
        "        ids = ids,\n",
        "        mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        "      )\n",
        "\n",
        "      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "  return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "sai52AShG_E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "def run(train_data_loader, valid_data_loader):\n",
        "  device = torch.device(\"cuda\")\n",
        "  model = BERTBaseUncased()\n",
        "  model.to(device)\n",
        "\n",
        "  param_optimizer = list(model.named_parameters())\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_parameters = [\n",
        "    {'params' : [p for n, p in param_optimizer if not any (nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "    {'params' : [p for n, p in param_optimizer if any (nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "  ]\n",
        "\n",
        "  num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "  optimizer = AdamW(optimizer_parameters, lr = LR)\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0,\n",
        "                                              num_training_steps = num_train_steps)\n",
        "\n",
        "  best_accuracy = 0\n",
        "  for epoch in range(EPOCHS):\n",
        "    train(train_data_loader, model, optimizer, device, scheduler)\n",
        "    outputs, targets = eval(valid_data_loader, model, device)\n",
        "    # targets = np.array(targets) >= 0.5\n",
        "    accuracy = metrics.roc_auc_score(targets, outputs)\n",
        "    print((f\"AUC Score = {accuracy}\"))\n",
        "    if accuracy > best_accuracy:\n",
        "      torch.save(model.state_dict(), MODEL_PATH)\n",
        "      best_accuarcy = accuracy"
      ],
      "metadata": {
        "id": "i7EtrYw6KEAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "\n",
        "MAX_LEN = 100\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 1\n",
        "LR = 1e-5\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Colab Notebooks/model.pt\"\n",
        "TOKENIZER = transformers.BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "_0fxVf42JbQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataset(\n",
        "    comment_text = df_train.clean_comment_text.values,\n",
        "    target = df_train.toxic.values\n",
        ")\n",
        "train_data_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = TRAIN_BATCH_SIZE,\n",
        "    num_workers = 2,\n",
        "    shuffle=True\n",
        ")\n",
        "valid_dataset = BERTDataset(\n",
        "    comment_text = df_valid.comment_text.values,\n",
        "    target = df_valid.toxic.values\n",
        ")\n",
        "\n",
        "valid_data_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size = VALID_BATCH_SIZE,\n",
        "    num_workers = 1,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "lpt6wnFjcPXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(train_data_loader, valid_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDrPygQf3Xsa",
        "outputId": "e6add6e6-15e6-44c4-d43a-f9ec85664a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "100%|██████████| 7/7 [00:02<00:00,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_id = 6 batch_loss = 0.33761924505233765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 7/7 [00:00<00:00,  9.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC Score = 0.4167257264351524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction.py\n",
        "\n",
        "def pred():\n",
        "  model = torch.load('/content/drive/MyDrive/Colab Notebooks/model.pt')\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    preds = []\n",
        "    for batch_id, (token_ids, attention_masks) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "      token_ids = token_ids.to(device)\n",
        "      attention_masks = attention_masks.to(device)\n",
        "      output = model(token_ids, attention_masks)[0]\n",
        "      logits = torch.nn.functional.softmax(output, dim=1).detach().cpu().numpy()\n",
        "      preds.extend(logits)"
      ],
      "metadata": {
        "id": "PUyds6Kl93u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이하 코드는 테스트 코드"
      ],
      "metadata": {
        "id": "NHh9uzOuiYCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JqERl70S2OJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YKiVmtp32OF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3AvjiHaC2OCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트코드"
      ],
      "metadata": {
        "id": "FV4Ba5qwiX_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "bert = transformers.BertModel.from_pretrained('bert-base-multilingual-cased').to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "e7400736a8c44148ac737f33af6bc103",
            "3eeb5a7ff311441d9d9d0b90f5951629",
            "ec56ae0e641a4282887d8c373584022e",
            "d7a6a45f061c468899f26b79e1d2d806",
            "fd112ab14443468f90adfaeb906eb4cb",
            "337b2d3655c54b089a3cd1ff0181986f",
            "368cf1536d2f4c45a9e87aa32a0fedb9",
            "440294808f7b4c25959018506dc26231",
            "6a5caffc4c184a96978f06362364fe50",
            "09162f2e24854fbfb73665f978456d05",
            "9f01c972a9644c039890ea852889ad4d"
          ]
        },
        "id": "k3HWKEEfpVlQ",
        "outputId": "c149e9db-70e8-4995-daea-17e20b965594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7400736a8c44148ac737f33af6bc103"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "# device = torch.device('cpu')\n",
        "model = BERTBaseUncased().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "3iLyha4EAik6",
        "outputId": "31fa9160-4d9c-40ac-9315-ff25be6ec0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-1beb3ca5891b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# device = torch.device('cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTBaseUncased\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    904\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, data in tqdm(enumerate(valid_data_loader), total=len(valid_data_loader)):\n",
        "   ids = data['ids']\n",
        "   token_type_ids = data['token_type_ids']\n",
        "   mask = data['mask']\n",
        "   targets = data['target']\n",
        "\n",
        "   ids = ids.to(device, dtype=torch.long)\n",
        "   token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "   mask = mask.to(device, dtype=torch.long)\n",
        "   targets = targets.to(device, dtype=torch.long)\n",
        "   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTg589-HiW3T",
        "outputId": "d2ac7b98-6d46-41b6-da5a-556137a8dc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/7 [00:00<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids)\n",
        "print(token_type_ids)\n",
        "print(mask)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jvjtMbcKdoJ",
        "outputId": "4db69cd9-224d-4124-9f14-2f1a4aaee655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   101,  10247,    120,  ...,      0,      0,      0],\n",
            "        [   101,    173,  10237,  ...,      0,      0,      0],\n",
            "        [   101,  13697, 100025,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  21583,  10123,  ...,  10418,    102,      0],\n",
            "        [   101,  10414,  53543,  ...,      0,      0,      0],\n",
            "        [   101,  10294,  19325,  ...,      0,      0,      0]])\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n",
            "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])\n",
            "tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert = transformers.BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
        "outputs = bert(\n",
        "        ids,\n",
        "        attention_mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6BbAk0QKy30",
        "outputId": "e87b6851-05ae-45fc-8143-c2cef492af54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX_qFIHYOHLP",
        "outputId": "c9381352-645b-4c79-f4ea-d461dbb4fff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 100, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(outputs[0], 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHP5wQZGMsEZ",
        "outputId": "5110f0bf-a1c7-4ce0-d931-b8b313fca585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([[0.8341, 0.8097, 1.5347,  ..., 1.4086, 0.9169, 0.8884],\n",
              "        [0.5375, 0.4361, 1.7747,  ..., 0.7926, 0.3058, 0.3963],\n",
              "        [0.7145, 0.3961, 1.2925,  ..., 1.0917, 0.5830, 1.3070],\n",
              "        ...,\n",
              "        [0.2507, 1.0089, 1.3007,  ..., 0.7810, 0.5252, 1.1897],\n",
              "        [0.4364, 0.8533, 1.5533,  ..., 1.3696, 0.9986, 1.4865],\n",
              "        [0.5254, 0.4245, 1.7083,  ..., 1.2749, 1.0420, 1.2905]],\n",
              "       device='cuda:0', grad_fn=<MaxBackward0>), ...)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_pooling = torch.mean(outputs[0], 1)\n",
        "max_pooling = torch.max(outputs[0], 1)[0]\n",
        "print(mean_pooling)\n",
        "print(max_pooling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsAFKtUkK-Mq",
        "outputId": "99c616f4-839d-483f-d7f8-2e7bdadbbf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0586, -0.2672, -0.1470,  ...,  0.0343,  0.0246,  0.3047],\n",
            "        [-0.5249,  0.1883,  0.0353,  ...,  0.3419,  0.2138,  0.0042],\n",
            "        [-0.1869, -0.5305,  0.3124,  ...,  0.0755, -0.0814,  0.4429],\n",
            "        ...,\n",
            "        [-0.0969, -0.1655,  0.3459,  ...,  0.3441,  0.0966,  0.3250],\n",
            "        [ 0.0120, -0.3983,  0.1737,  ...,  0.0564,  0.1642,  0.0659],\n",
            "        [-0.3242, -0.3836,  0.1232,  ...,  0.2428, -0.0313,  0.4149]],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "tensor([[1.0278, 0.4594, 1.3534,  ..., 1.2225, 0.8621, 1.6045],\n",
            "        [0.3587, 0.7318, 1.4748,  ..., 1.2207, 0.9245, 0.7660],\n",
            "        [0.5443, 0.4104, 1.4537,  ..., 1.1046, 0.9373, 1.3056],\n",
            "        ...,\n",
            "        [0.9907, 1.0772, 1.5230,  ..., 1.4751, 1.0895, 1.1570],\n",
            "        [0.8003, 0.5594, 1.3066,  ..., 1.1569, 1.0621, 0.9255],\n",
            "        [0.4644, 0.5846, 1.5499,  ..., 1.6675, 1.2249, 1.4496]],\n",
            "       grad_fn=<MaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat = torch.cat((mean_pooling, max_pooling),1)\n",
        "print(cat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JZhqtbxL4CG",
        "outputId": "d1d22cc1-828e-4208-8f39-b71fc2225af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0586, -0.2672, -0.1470,  ...,  1.2225,  0.8621,  1.6045],\n",
            "        [-0.5249,  0.1883,  0.0353,  ...,  1.2207,  0.9245,  0.7660],\n",
            "        [-0.1869, -0.5305,  0.3124,  ...,  1.1046,  0.9373,  1.3056],\n",
            "        ...,\n",
            "        [-0.0969, -0.1655,  0.3459,  ...,  1.4751,  1.0895,  1.1570],\n",
            "        [ 0.0120, -0.3983,  0.1737,  ...,  1.1569,  1.0621,  0.9255],\n",
            "        [-0.3242, -0.3836,  0.1232,  ...,  1.6675,  1.2249,  1.4496]],\n",
            "       grad_fn=<CatBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = nn.Linear(768*2, 1).to(device)"
      ],
      "metadata": {
        "id": "9itl9ujnp9Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = out(cat)"
      ],
      "metadata": {
        "id": "8DbsVNBTO85v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu_Ug2NTQVVQ",
        "outputId": "0fe68123-1d7b-4683-c525-6f3b5801e808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3792],\n",
              "        [0.5491],\n",
              "        [0.2730],\n",
              "        [0.3773],\n",
              "        [0.4561],\n",
              "        [0.2064],\n",
              "        [0.2225],\n",
              "        [0.3269],\n",
              "        [0.2739],\n",
              "        [0.5427],\n",
              "        [0.3959],\n",
              "        [0.5336],\n",
              "        [0.5073],\n",
              "        [0.6041],\n",
              "        [0.2007],\n",
              "        [0.4927]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "  return nn.BCEWithLogitsLoss()(outputs, targets.float().view(-1, 1))"
      ],
      "metadata": {
        "id": "7edqezZcRX_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn(pred, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk2jYp9RQDCw",
        "outputId": "4176f51a-31a0-4525-ab5e-db20084bf401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7774, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(\n",
        "    ids = ids,\n",
        "    mask = mask,\n",
        "    token_type_ids = token_type_ids\n",
        ")"
      ],
      "metadata": {
        "id": "y8mdGtB_rQVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJiuK8ArdqX",
        "outputId": "7d057950-d564-40eb-d300-4cca499d3a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1379],\n",
              "        [-0.1046],\n",
              "        [-0.1857],\n",
              "        [-0.0685],\n",
              "        [-0.1720],\n",
              "        [-0.1240],\n",
              "        [-0.0849],\n",
              "        [-0.0676],\n",
              "        [-0.0986],\n",
              "        [-0.1321],\n",
              "        [-0.0929],\n",
              "        [-0.1777],\n",
              "        [-0.0874],\n",
              "        [-0.2104],\n",
              "        [-0.0668],\n",
              "        [-0.0582]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPEf5VEargA6",
        "outputId": "5ce5d294-0b01-4150-e274-feacb2823305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(targets.view(-1, 1).float(), outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "989vo_dcKFnS",
        "outputId": "2e0a4d31-0d48-462a-e220-65f39fff2c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0., device='cuda:0', grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(targets.float(), outputs)"
      ],
      "metadata": {
        "id": "Bel6XK85rbZO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "e3a49e73-bcf2-47b6-d783-99b4477802e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-40a4c7b33c7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-035613067e6f>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(outputs, targets)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuwkDGTErpVS",
        "outputId": "48b284cb-259c-4da5-d2c9-489b8df1aaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0., device='cuda:0', grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = bert(\n",
        "        ids,\n",
        "        attention_mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        ")"
      ],
      "metadata": {
        "id": "ZUw_F-OQpcBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out(outputs[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4nPrRC5pl1W",
        "outputId": "5f286de5-a77a-4c1a-c106-59d4b64c894c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4839],\n",
              "        [0.4113],\n",
              "        [0.4250],\n",
              "        [0.3696],\n",
              "        [0.3300],\n",
              "        [0.2585],\n",
              "        [0.2929],\n",
              "        [0.2718],\n",
              "        [0.4765],\n",
              "        [0.4958],\n",
              "        [0.4319],\n",
              "        [0.3376],\n",
              "        [0.3643],\n",
              "        [0.4480],\n",
              "        [0.2355],\n",
              "        [0.3274]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E7diU20SigXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0f97dc-dd4d-43fd-b546-f056d41aac99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bert = transformers.BertModel.from_pretrained('bert-base-multilingual-cased').to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtaEHjDYikqQ",
        "outputId": "da344c77-89fe-4d15-aa0c-fcff6c4cb424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(\n",
        "        ids = ids,\n",
        "        mask = mask,\n",
        "        token_type_ids = token_type_ids)"
      ],
      "metadata": {
        "id": "NVxgNJ3mjYEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA2aqQDKomel",
        "outputId": "640ef0b5-ef78-4667-d858-b92b99f5499a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6342],\n",
              "        [-0.5819],\n",
              "        [-0.5279],\n",
              "        [-0.5547],\n",
              "        [ 0.1543],\n",
              "        [-0.4455],\n",
              "        [-0.5732],\n",
              "        [-0.6738],\n",
              "        [-0.4307],\n",
              "        [-0.5857],\n",
              "        [-0.3221],\n",
              "        [-0.5132],\n",
              "        [ 0.1230],\n",
              "        [-0.4605],\n",
              "        [-0.5499],\n",
              "        [-0.6433]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, targets = eval(valid_data_loader, model, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6PhIMJOqgXL",
        "outputId": "c612233a-a9ce-403e-8887-715ad6dc7328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:01<00:00,  9.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POXxFCr64W0_",
        "outputId": "0176adc5-4ee9-4a66-f3fc-d7b1fd14eaa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.4376993477344513],\n",
              " [0.5473430752754211],\n",
              " [0.4304685592651367],\n",
              " [0.3696940839290619],\n",
              " [0.3778122663497925],\n",
              " [0.434233158826828],\n",
              " [0.43217146396636963],\n",
              " [0.4821430742740631],\n",
              " [0.3803848922252655],\n",
              " [0.3944300413131714],\n",
              " [0.5571368336677551],\n",
              " [0.3973301947116852],\n",
              " [0.43737703561782837],\n",
              " [0.5570463538169861],\n",
              " [0.4305109679698944],\n",
              " [0.4362465739250183],\n",
              " [0.4069691002368927],\n",
              " [0.42568057775497437],\n",
              " [0.3767576813697815],\n",
              " [0.43503254652023315],\n",
              " [0.42154985666275024],\n",
              " [0.4401720464229584],\n",
              " [0.3826456367969513],\n",
              " [0.4007130265235901],\n",
              " [0.3964690566062927],\n",
              " [0.43989676237106323],\n",
              " [0.4022636413574219],\n",
              " [0.3940058946609497],\n",
              " [0.4127604365348816],\n",
              " [0.4376904368400574],\n",
              " [0.3904869258403778],\n",
              " [0.39702335000038147],\n",
              " [0.4382345974445343],\n",
              " [0.5560024380683899],\n",
              " [0.3747329115867615],\n",
              " [0.3790303170681],\n",
              " [0.43346527218818665],\n",
              " [0.4012080430984497],\n",
              " [0.4120001792907715],\n",
              " [0.5309929847717285],\n",
              " [0.4065152406692505],\n",
              " [0.5681859850883484],\n",
              " [0.38822999596595764],\n",
              " [0.4211895763874054],\n",
              " [0.4488644003868103],\n",
              " [0.41345593333244324],\n",
              " [0.39774033427238464],\n",
              " [0.38944995403289795],\n",
              " [0.3927995264530182],\n",
              " [0.41715356707572937],\n",
              " [0.40130794048309326],\n",
              " [0.5250956416130066],\n",
              " [0.3970165550708771],\n",
              " [0.38039571046829224],\n",
              " [0.39434462785720825],\n",
              " [0.4599442183971405],\n",
              " [0.4236721694469452],\n",
              " [0.45436543226242065],\n",
              " [0.39004257321357727],\n",
              " [0.42073458433151245],\n",
              " [0.409529447555542],\n",
              " [0.4088393747806549],\n",
              " [0.48133939504623413],\n",
              " [0.37418481707572937],\n",
              " [0.40156394243240356],\n",
              " [0.4295848309993744],\n",
              " [0.4085920751094818],\n",
              " [0.394776314496994],\n",
              " [0.4548306465148926],\n",
              " [0.39815038442611694],\n",
              " [0.3728174567222595],\n",
              " [0.4216894805431366],\n",
              " [0.5147594809532166],\n",
              " [0.4360419809818268],\n",
              " [0.3844199776649475],\n",
              " [0.4557246267795563],\n",
              " [0.4145445227622986],\n",
              " [0.40472176671028137],\n",
              " [0.3923597037792206],\n",
              " [0.3676266074180603],\n",
              " [0.4305307865142822],\n",
              " [0.4503531754016876],\n",
              " [0.42314648628234863],\n",
              " [0.37968680262565613],\n",
              " [0.402629017829895],\n",
              " [0.4445572793483734],\n",
              " [0.4892417788505554],\n",
              " [0.4324810206890106],\n",
              " [0.3897212743759155],\n",
              " [0.3772260546684265],\n",
              " [0.3859063684940338],\n",
              " [0.3862154185771942],\n",
              " [0.36321818828582764],\n",
              " [0.4300920069217682],\n",
              " [0.4048355221748352],\n",
              " [0.40521323680877686],\n",
              " [0.4470181167125702],\n",
              " [0.4827624559402466],\n",
              " [0.4376904368400574],\n",
              " [0.41668349504470825],\n",
              " [0.3999153673648834],\n",
              " [0.41196542978286743],\n",
              " [0.39010995626449585],\n",
              " [0.43547314405441284],\n",
              " [0.5676358938217163],\n",
              " [0.4098008871078491],\n",
              " [0.4192216992378235],\n",
              " [0.4376904368400574],\n",
              " [0.41745054721832275],\n",
              " [0.4137994945049286],\n",
              " [0.40491384267807007],\n",
              " [0.4130139946937561],\n",
              " [0.4035201668739319],\n",
              " [0.42264115810394287],\n",
              " [0.43960657715797424],\n",
              " [0.38818153738975525],\n",
              " [0.3836292624473572],\n",
              " [0.4362310469150543],\n",
              " [0.4776701331138611],\n",
              " [0.3724040389060974],\n",
              " [0.4316006004810333],\n",
              " [0.41848549246788025],\n",
              " [0.3804033100605011],\n",
              " [0.43361973762512207],\n",
              " [0.36593425273895264],\n",
              " [0.397956520318985],\n",
              " [0.4217506945133209],\n",
              " [0.3945493996143341],\n",
              " [0.35584181547164917],\n",
              " [0.3943708837032318],\n",
              " [0.4402797520160675],\n",
              " [0.3631671071052551],\n",
              " [0.4008578956127167],\n",
              " [0.42794719338417053],\n",
              " [0.4049045443534851],\n",
              " [0.4122646749019623],\n",
              " [0.4206793010234833],\n",
              " [0.40776869654655457],\n",
              " [0.4057636260986328],\n",
              " [0.4048807621002197],\n",
              " [0.3962359130382538],\n",
              " [0.409175306558609],\n",
              " [0.37459537386894226],\n",
              " [0.39906203746795654],\n",
              " [0.39592161774635315],\n",
              " [0.3977450132369995],\n",
              " [0.41798192262649536],\n",
              " [0.4111344516277313],\n",
              " [0.4249248802661896],\n",
              " [0.4182682931423187],\n",
              " [0.4239251911640167],\n",
              " [0.45585981011390686],\n",
              " [0.4352165758609772],\n",
              " [0.38223549723625183],\n",
              " [0.4049658179283142],\n",
              " [0.44332003593444824],\n",
              " [0.40297290682792664],\n",
              " [0.4221184551715851],\n",
              " [0.4432137906551361],\n",
              " [0.4140409231185913],\n",
              " [0.4235721826553345],\n",
              " [0.3819528818130493],\n",
              " [0.4183976352214813],\n",
              " [0.3689381182193756],\n",
              " [0.4619782269001007],\n",
              " [0.37336844205856323],\n",
              " [0.3489972949028015],\n",
              " [0.39819207787513733],\n",
              " [0.3724908232688904],\n",
              " [0.40337198972702026],\n",
              " [0.41523677110671997],\n",
              " [0.4009683430194855],\n",
              " [0.4065113961696625],\n",
              " [0.40577471256256104],\n",
              " [0.4477123022079468],\n",
              " [0.43058037757873535],\n",
              " [0.4772869944572449],\n",
              " [0.4373820424079895],\n",
              " [0.38725849986076355],\n",
              " [0.3451903760433197],\n",
              " [0.43286415934562683],\n",
              " [0.44005268812179565],\n",
              " [0.4083162248134613],\n",
              " [0.3596281409263611],\n",
              " [0.37434035539627075],\n",
              " [0.3928764760494232],\n",
              " [0.5404630303382874],\n",
              " [0.3915674686431885],\n",
              " [0.4239480793476105],\n",
              " [0.4259911775588989],\n",
              " [0.42373374104499817],\n",
              " [0.4394967555999756],\n",
              " [0.42829450964927673],\n",
              " [0.40453994274139404],\n",
              " [0.36412447690963745],\n",
              " [0.4046563506126404],\n",
              " [0.40924686193466187],\n",
              " [0.45543450117111206],\n",
              " [0.4143419861793518],\n",
              " [0.3803717792034149]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.roc_auc_score(targets, outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kphvTxGapulG",
        "outputId": "946a268a-40a4-4ed1-ef45-2125619c6a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZdKJ0T5ouzV",
        "outputId": "05c1d671-f186-45e7-be6e-24bdcb234db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(targets) >= 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ly0AtKblzOI",
        "outputId": "5c0ed90e-0c53-409e-b3da-f3f768387985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.array(targets) >= 0.5\n",
        "    accuracy = metrics.roc_auc_score(targets, outputs)"
      ],
      "metadata": {
        "id": "UePjv0-nirS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "11bf28bb-4b9b-4cef-8bf9-76eb44c2f763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-e518f864067f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'view'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = nn.Linear(768, 1).to(device)"
      ],
      "metadata": {
        "id": "3NDeWTgNmaNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = out(outputs[0])"
      ],
      "metadata": {
        "id": "w3O1BealmV5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o = torch.sigmoid(output[0]).cpu().detach().numpy().tolist()"
      ],
      "metadata": {
        "id": "TwSf4n4Y0QFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = targets.cpu().detach().numpy().tolist()\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXX9lSUatcHA",
        "outputId": "4a67171f-d3eb-4328-c6b2-c217f9234786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = F.cross_entropy(output, targets.view(-1, 1))"
      ],
      "metadata": {
        "id": "usWAzPKctj4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = np.array(t) >= 0.5\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhIXg7hAt9KG",
        "outputId": "28b72899-1c5b-46ae-aa95-c2cbb4577f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.roc_auc_score(t2, o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "daamrfvsw4Xc",
        "outputId": "02cb7369-b197-4905-e08e-254e7fbb6331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-eacf23537d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         )\n\u001b[1;32m    574\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         raise ValueError(\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"is not defined in that case.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = metrics.roc_auc_score(targets, outputs)"
      ],
      "metadata": {
        "id": "rWm7eYfhydib",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "b45c6016-2e9d-4b82-85ee-43405e806ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-e18f1a8406d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     if y_type == \"multiclass\" or (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m             raise ValueError(\n\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             )\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qVZe5Mhoj354"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}